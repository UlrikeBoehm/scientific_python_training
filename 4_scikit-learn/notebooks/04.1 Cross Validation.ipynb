{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation and scoring methods\n",
    "=====================================\n",
    "To evaluate how well our supervised models generalize, so far we split our data into a training and a test set:\n",
    "<img src=\"figures/train_test_split.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, often (labeled) data is precious, and this approach lets us only use ~ 3/4 of our data for training. On the other hand, we will only ever try to apply our model 1/4 of our data for testing.\n",
    "A common way to use more of the data to built a model, but also get a more robust estimate of the generalization performance is cross-validation.\n",
    "In cross-validation, the data is split repeatedly into a training and test-set, with a separate model built for every pair. The test-set scores are then aggregated for a more robust estimate.\n",
    "The most common way to do cross-validation is k-fold cross-validation, in which the data is first split into k (often 5 or 10) equal-sized folds, and then for each iteration, one of the k folds is used as test data, and the rest as training data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cross_validation.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, each data point will be in the test-set exactly once, and we can use all but a k'th of the data for training.\n",
    "Let us apply this technique to evaluate the KNeighborsClassifier algorithm on the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "classifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels in iris are sorted, which means that if we split the data as illustrated above, the first fold will only have the label 0 in it, while the last one will only have the label 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid this problem in evaluation, we first shuffle our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1 2 0 0 2 1 0 0\n",
      " 1 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2 2 0 0 0 1 1 0\n",
      " 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1 1 1 0 0 0 2 1\n",
      " 2 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "permutation = rng.permutation(len(X))\n",
    "X, y = X[permutation], y[permutation]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implementing cross-validation is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "n_samples = len(X)\n",
    "fold_size = n_samples // k\n",
    "scores = []\n",
    "masks = []\n",
    "for fold in range(k):\n",
    "    # generate a boolean mask for the test set in this fold\n",
    "    test_mask = np.zeros(n_samples, dtype=bool)\n",
    "    test_mask[fold * fold_size : (fold + 1) * fold_size] = True\n",
    "    # store the mask for visualization\n",
    "    masks.append(test_mask)\n",
    "    # create training and test sets using this mask\n",
    "    X_test, y_test = X[test_mask], y[test_mask]\n",
    "    X_train, y_train = X[~test_mask], y[~test_mask]\n",
    "    # fit the classifier\n",
    "    classifier.fit(X_train, y_train)\n",
    "    # compute the score and record it\n",
    "    scores.append(classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that our test mask does the right thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a162ac6a0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.matshow(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's look a the scores we computed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 0.9, 1.0, 1.0, 0.9333333333333333]\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a rather wide spectrum of scores from 90% correct to 100% correct. If we only did a single split, we might have gotten either answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As cross-validation is such a common pattern in machine learning, there are functions to do the above for you with much more flexibility and less code.\n",
    "The ``sklearn.cross_validation`` module has all functions related to cross validation. There easiest function is ``cross_val_score`` which takes an estimator and a dataset, and will do all of the splitting for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98039216 0.98039216 0.95833333]\n",
      "0.9730392156862745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/squiresrb/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(classifier, X, y)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the function uses three folds by default. You can change the number of folds using the cv argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 1.        , 0.93333333])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(classifier, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also helper objects in the cross-validation module that will generate indices for you for all kinds of different cross-validation methods, including k-fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit, LeavePGroupsOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, cross_val_score will use ``StratifiedKFold`` for classification, which ensures that the class proportions in the dataset are reflected in each fold. If you have a binary classification dataset with 90% of data point belonging to class 0, that would mean that in each fold, 90% of datapoints would belong to class 0.\n",
    "If you would just use KFold cross-validation, it is likely that you would generate a split that only contains class 0.\n",
    "It is generally a good idea to use ``StratifiedKFold`` whenever you do classification.\n",
    "\n",
    "``StratifiedKFold`` would also remove our need to shuffle ``iris``.\n",
    "Let's see what kinds of folds it generates on the unshuffled iris dataset.\n",
    "Each cross-validation class is a generator of sets of training and test indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StratifiedKFold in module sklearn.model_selection._split:\n",
      "\n",
      "class StratifiedKFold(_BaseKFold)\n",
      " |  StratifiedKFold(n_splits='warn', shuffle=False, random_state=None)\n",
      " |  \n",
      " |  Stratified K-Folds cross-validator\n",
      " |  \n",
      " |  Provides train/test indices to split data in train/test sets.\n",
      " |  \n",
      " |  This cross-validation object is a variation of KFold that returns\n",
      " |  stratified folds. The folds are made by preserving the percentage of\n",
      " |  samples for each class.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_splits : int, default=3\n",
      " |      Number of folds. Must be at least 2.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |          ``n_splits`` default value will change from 3 to 5 in v0.22.\n",
      " |  \n",
      " |  shuffle : boolean, optional\n",
      " |      Whether to shuffle each stratification of the data before splitting\n",
      " |      into batches.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default=None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`. Used when ``shuffle`` == True.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.model_selection import StratifiedKFold\n",
      " |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      " |  >>> y = np.array([0, 0, 1, 1])\n",
      " |  >>> skf = StratifiedKFold(n_splits=2)\n",
      " |  >>> skf.get_n_splits(X, y)\n",
      " |  2\n",
      " |  >>> print(skf)  # doctest: +NORMALIZE_WHITESPACE\n",
      " |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      " |  >>> for train_index, test_index in skf.split(X, y):\n",
      " |  ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      " |  ...    X_train, X_test = X[train_index], X[test_index]\n",
      " |  ...    y_train, y_test = y[train_index], y[test_index]\n",
      " |  TRAIN: [1 3] TEST: [0 2]\n",
      " |  TRAIN: [0 2] TEST: [1 3]\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  Train and test sizes may be different in each fold, with a difference of at\n",
      " |  most ``n_classes``.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StratifiedKFold\n",
      " |      _BaseKFold\n",
      " |      abc.NewBase\n",
      " |      BaseCrossValidator\n",
      " |      abc.NewBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_splits='warn', shuffle=False, random_state=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  split(self, X, y, groups=None)\n",
      " |      Generate indices to split data into training and test set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training data, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |          Note that providing ``y`` is sufficient to generate the splits and\n",
      " |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      " |          ``X`` instead of actual training data.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          The target variable for supervised learning problems.\n",
      " |          Stratification is done based on the y labels.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Yields\n",
      " |      ------\n",
      " |      train : ndarray\n",
      " |          The training set indices for that split.\n",
      " |      \n",
      " |      test : ndarray\n",
      " |          The testing set indices for that split.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Randomized CV splitters may return different results for each call of\n",
      " |      split. You can make the results identical by setting ``random_state``\n",
      " |      to an integer.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _BaseKFold:\n",
      " |  \n",
      " |  get_n_splits(self, X=None, y=None, groups=None)\n",
      " |      Returns the number of splitting iterations in the cross-validator\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      y : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      groups : object\n",
      " |          Always ignored, exists for compatibility.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      n_splits : int\n",
      " |          Returns the number of splitting iterations in the cross-validator.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseCrossValidator:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from abc.NewBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 22 23 24\n",
      " 25 26 30 33 34 40]\n",
      "[21 27 28 29 31 32 35 36 37 38 39 41 42 43 44 45 46 47 48 49 50 51 54 55\n",
      " 56 57 61 68 69 72]\n",
      "[52 53 58 59 60 62 63 64 65 66 67 70 71 73 74 75 76 78 80 82 83 84 85 86\n",
      " 87 88 91 93 96 97]\n",
      "[ 77  79  81  89  90  92  94  95  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 127]\n",
      "[119 120 121 122 123 124 125 126 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5) #iris.target\n",
    "for train, test in cv.split(iris.target, y):\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are a couple of samples from the beginning, then from the middle, and then from the end, in each of the folds.\n",
    "This way, the class ratios are preserved. Let's visualize the split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv(cv, data, y, n_samples):\n",
    "    masks = []\n",
    "    for train, test in cv.split(data, y):\n",
    "        mask = np.zeros(n_samples, dtype=bool)\n",
    "        mask[test] = 1\n",
    "        masks.append(mask)\n",
    "    \n",
    "    plt.matshow(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cv(StratifiedKFold(n_splits=5), iris.target, y, len(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, again the standard KFold, that ignores the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got multiple values for argument 'n_splits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-80e4dd0968b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got multiple values for argument 'n_splits'"
     ]
    }
   ],
   "source": [
    "plot_cv(KFold(len(iris.target), n_splits=5), len(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that increasing the number of folds will give you a larger training dataset, but will lead to more repetitions, and therefore a slower evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(KFold(len(iris.target), n_folds=10), len(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another helpful cross-validation generator is ``ShuffleSplit``. This generator simply splits of a random portion of the data repeatedly. This allows the user to specify the number of repetitions and the training set size independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(ShuffleSplit(len(iris.target), n_iter=5, test_size=.2), len(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a more robust estimate, you can just increase the number of iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(ShuffleSplit(len(iris.target), n_iter=20, test_size=.2), len(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use all of these cross-validation generators with the cross_val_score method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(len(iris.target), n_iter=5, test_size=.2)\n",
    "cross_val_score(classifier, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
